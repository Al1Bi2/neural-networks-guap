{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQqPS3EAs5Pq",
        "outputId": "93374d30-410e-4e16-81e8-f1795d0162f1"
      },
      "id": "fQqPS3EAs5Pq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5b1c5d3c-f2e7-4769-8274-928d803c7da8",
      "metadata": {
        "id": "5b1c5d3c-f2e7-4769-8274-928d803c7da8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "#from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "338dbb11-686f-40c6-9543-6d5084a64d16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "338dbb11-686f-40c6-9543-6d5084a64d16",
        "outputId": "c02555b5-c16c-4625-cbae-ab22e831b024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "seed = 7\n",
        "print(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7e231f4a-660a-49d4-8c9c-1984fffcccd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e231f4a-660a-49d4-8c9c-1984fffcccd7",
        "outputId": "d366ea54-0f91-4747-dc5e-c2c3da4b7e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# Загрузка данных\n",
        "max_features = 20000\n",
        "(x_data1, y_data1), (x_data2, y_data2) = imdb.load_data(num_words=max_features,seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d16780e6-91a3-4f23-b4fa-144bf023d57c",
      "metadata": {
        "id": "d16780e6-91a3-4f23-b4fa-144bf023d57c"
      },
      "outputs": [],
      "source": [
        "max_review_length = 2000\n",
        "x_data = np.concatenate([x_data1, x_data2], axis=0)\n",
        "y_data = np.concatenate([y_data1, y_data2], axis=0)\n",
        "x_data = pad_sequences(x_data, maxlen=max_review_length,value = 0,padding = 'post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c8a32b22-d168-46f4-b9dd-ec858659cf41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8a32b22-d168-46f4-b9dd-ec858659cf41",
        "outputId": "ca407f09-6eb2-49b9-8fb1-ad72b8778875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42500, 2000) (6000, 2000) (1500, 2000)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(x_data, y_data, test_size=0.15, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Проверка размеров выборок\n",
        "print(x_train.shape, x_val.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b3644b-ac0e-4397-a786-a4255d2d5e6f",
      "metadata": {
        "id": "89b3644b-ac0e-4397-a786-a4255d2d5e6f"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "embedding_vecor_length = 300\n",
        "# Модель\n",
        "model_cnn = Sequential([\n",
        "    Embedding(input_dim=max_features, output_dim=embedding_vecor_length),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.summary()\n",
        "# Обучение\n",
        "print(type(x_train[0][0]))\n",
        "history_cnn  = model_cnn.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,verbose =1,validation_data=(x_val,y_val)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Папка для хранения GloVe\n",
        "glove_dir = './glove'\n",
        "\n",
        "if not os.path.exists(glove_dir):\n",
        "    os.makedirs(glove_dir)\n",
        "\n",
        "# URL для скачивания GloVe\n",
        "glove_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "glove_zip_path = os.path.join(glove_dir, 'glove.6B.zip')\n",
        "\n",
        "# Скачивание\n",
        "if not os.path.exists(glove_zip_path):\n",
        "    print(\"Скачивание GloVe...\")\n",
        "    urllib.request.urlretrieve(glove_url, glove_zip_path)\n",
        "\n",
        "# Распаковка\n",
        "if not os.path.exists(os.path.join(glove_dir, 'glove.6B.300d.txt')):\n",
        "    print(\"Распаковка GloVe...\")\n",
        "    with zipfile.ZipFile(glove_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(glove_dir)\n",
        "\n",
        "print(\"GloVe готов к использованию.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl6Gii0h1NSG",
        "outputId": "df006d46-a199-4566-a5eb-1b239beeee9f"
      },
      "id": "dl6Gii0h1NSG",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скачивание GloVe...\n",
            "Распаковка GloVe...\n",
            "GloVe готов к использованию.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "# Загрузка GloVe\n",
        "embedding_dim = 300\n",
        "glove_file = './glove/glove.6B.300d.txt'\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHiRL0583zAa",
        "outputId": "4024dbd8-515a-47e4-f260-f2aa5a794d7a"
      },
      "id": "GHiRL0583zAa",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.6B.100d.txt  glove.6B.200d.txt  glove.6B.300d.txt  glove.6B.50d.txt  glove.6B.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание матрицы эмбеддингов\n",
        "word_index = imdb.get_word_index()\n",
        "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_features:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "c6N7favQ4OfS"
      },
      "id": "c6N7favQ4OfS",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "80cf8e87-888a-4a33-9955-5170fc40a34c",
      "metadata": {
        "id": "80cf8e87-888a-4a33-9955-5170fc40a34c"
      },
      "outputs": [],
      "source": [
        "# Построение полносвязной сети\n",
        "model_dense = Sequential([\n",
        "    Embedding(input_dim=max_features,\n",
        "              output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix],\n",
        "              input_length=max_review_length,\n",
        "              trainable=False),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model_dense.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "history_dense = model_dense.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNBEwqnqz223",
        "outputId": "a5cec5a3-c104-41f4-ac65-8899d40c6181"
      },
      "id": "qNBEwqnqz223",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m146/333\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9:44\u001b[0m 3s/step - accuracy: 0.5066 - loss: 1.1333"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение графиков\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'{title} Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{title} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Визуализация\n",
        "plot_history(history_dense, 'Dense Model')"
      ],
      "metadata": {
        "id": "2DE_jN7Kz8YK"
      },
      "id": "2DE_jN7Kz8YK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "15423c70-1f29-437c-9a66-8ea655dc234b",
      "metadata": {
        "id": "15423c70-1f29-437c-9a66-8ea655dc234b"
      },
      "source": [
        "# Оценка моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a386e910-e4f8-48e5-97f9-b330fc8b2d1e",
      "metadata": {
        "id": "a386e910-e4f8-48e5-97f9-b330fc8b2d1e"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn = (model_cnn.predict(x_test) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b60d763-5c38-4527-be50-f6c0f09344c9",
      "metadata": {
        "id": "8b60d763-5c38-4527-be50-f6c0f09344c9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"CNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_cnn))\n",
        "plt.plot(history_cnn.history['accuracy'], label='CNN Train Accuracy')\n",
        "plt.plot(history_cnn.history['val_accuracy'], label='CNN Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc3bd64-177d-43d8-9d45-bd25d5551a5d",
      "metadata": {
        "id": "cbc3bd64-177d-43d8-9d45-bd25d5551a5d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6097acd9-2e94-4991-ae62-4ef397d4da46",
      "metadata": {
        "id": "6097acd9-2e94-4991-ae62-4ef397d4da46"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}